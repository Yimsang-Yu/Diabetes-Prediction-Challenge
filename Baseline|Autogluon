{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6477231c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-28T09:20:00.016915Z",
     "iopub.status.busy": "2025-12-28T09:20:00.016156Z",
     "iopub.status.idle": "2025-12-28T10:30:36.730687Z",
     "shell.execute_reply": "2025-12-28T10:30:36.729528Z"
    },
    "papermill": {
     "duration": 4236.729335,
     "end_time": "2025-12-28T10:30:36.741361",
     "exception": false,
     "start_time": "2025-12-28T09:20:00.012026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m515.2/515.2 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.9/98.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.4/74.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.26.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "datasets 4.4.1 requires pyarrow>=21.0.0, but you have pyarrow 20.0.0 which is incompatible.\r\n",
      "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 20.0.0 which is incompatible.\r\n",
      "bigframes 2.26.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\r\n",
      "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 20.0.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mtrain_path: /kaggle/input/playground-series-s5e12/train.csv\n",
      "test_path : /kaggle/input/playground-series-s5e12/test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.5.0\n",
      "Python Version:     3.12.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Sat Sep 27 10:16:09 UTC 2025\n",
      "CPU Count:          4\n",
      "Pytorch Version:    2.8.0+cu126\n",
      "CUDA Version:       CUDA is not available\n",
      "Memory Avail:       29.54 GB / 31.35 GB (94.2%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='zeroshot'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=5, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2025-12-28 09:20:44,949\tINFO worker.py:2023 -- Started a local Ray instance.\n",
      "/usr/local/lib/python3.12/dist-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n",
      "\t\tContext path: \"/kaggle/working/ag_diabetes_autml/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Beginning AutoGluon training ... Time limit = 880s\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m AutoGluon will save models to \"/kaggle/working/ag_diabetes_autml/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Train Data Rows:    622222\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Train Data Columns: 24\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Label Column:       diagnosed_diabetes\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tAvailable Memory:                    29397.77 MB\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tTrain Data (Original)  Memory Usage: 76.55 MB (0.3% of available memory)\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\t('category', []) :  9 | ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', ...]\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\t('float', [])    :  5 | ['diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio']\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\t('int', [])      : 10 | ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'systolic_bp', 'diastolic_bp', ...]\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\t('category', [])  :  6 | ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', ...]\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\t('float', [])     :  5 | ['diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio']\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\t('int', [])       : 10 | ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'systolic_bp', 'diastolic_bp', ...]\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t\t('int', ['bool']) :  3 | ['family_history_diabetes', 'hypertension_history', 'cardiovascular_history']\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t1.5s = Fit runtime\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t24 features in original data used to generate 24 features in processed data.\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tTrain Data (Processed) Memory Usage: 76.55 MB (0.3% of available memory)\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Data preprocessing and feature engineering runtime = 1.69s ...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 585.65s of the 878.69s of remaining time.\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.90%)\n",
      "\u001b[36m(pid=gcs_server)\u001b[0m [2025-12-28 09:21:07,744 E 60 60] (gcs_server) gcs_server.cc:303: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(_ray_fit pid=467)\u001b[0m /usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\n",
      "\u001b[36m(_ray_fit pid=467)\u001b[0m   if entities is not ():\n",
      "\u001b[33m(raylet)\u001b[0m [2025-12-28 09:21:14,072 E 135 135] (raylet) main.cc:979: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m [2025-12-28 09:21:21,519 E 177 259] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(_ray_fit pid=466)\u001b[0m /usr/local/lib/python3.12/dist-packages/sqlalchemy/orm/query.py:195: SyntaxWarning: \"is not\" with 'tuple' literal. Did you mean \"!=\"?\u001b[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=466)\u001b[0m   if entities is not ():\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "[2025-12-28 09:21:21,816 E 17 175] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(_ray_fit pid=467)\u001b[0m [2025-12-28 09:21:34,318 E 467 522] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(_ray_fit pid=464)\u001b[0m [2025-12-28 09:21:34,349 E 464 553] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=466)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.595547\n",
      "\u001b[36m(_ray_fit pid=464)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.598035\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=467)\u001b[0m \tRan out of time, early stopping on iteration 1829. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=467)\u001b[0m \t[1797]\tvalid_set's binary_logloss: 0.594901\n",
      "\u001b[36m(_ray_fit pid=466)\u001b[0m [2025-12-28 09:21:34,368 E 466 570] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=466)\u001b[0m \tRan out of time, early stopping on iteration 1834. Best iteration is:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=466)\u001b[0m \t[1827]\tvalid_set's binary_logloss: 0.594741\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=597)\u001b[0m [2025-12-28 09:26:28,363 E 597 618] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=597)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.597954\n",
      "\u001b[36m(_ray_fit pid=597)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.597245\n",
      "\u001b[36m(_ray_fit pid=597)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.596723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=597)\u001b[0m \tRan out of time, early stopping on iteration 3449. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=597)\u001b[0m \t[3294]\tvalid_set's binary_logloss: 0.596546\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t0.7066\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t530.36s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t216.79s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 289.57s of remaining time.\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.9 GB\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t0.7066\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t0.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t0.18s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 289.17s of the 289.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.96%)\n",
      "\u001b[36m(_ray_fit pid=705)\u001b[0m [2025-12-28 09:31:21,699 E 705 745] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(_ray_fit pid=836)\u001b[0m [2025-12-28 09:32:15,185 E 836 857] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t0.7063\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t91.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t19.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 187.07s of the 187.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.99%)\n",
      "\u001b[36m(_ray_fit pid=946)\u001b[0m [2025-12-28 09:33:03,705 E 946 968] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "\u001b[36m(_ray_fit pid=946)\u001b[0m \tRan out of time, early stopping on iteration 618. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=946)\u001b[0m \t[609]\tvalid_set's binary_logloss: 0.584713\n",
      "\u001b[36m(_ray_fit pid=947)\u001b[0m [2025-12-28 09:33:03,834 E 947 1052] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=948)\u001b[0m \tRan out of time, early stopping on iteration 621. Best iteration is:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=948)\u001b[0m \t[606]\tvalid_set's binary_logloss: 0.585136\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=1075)\u001b[0m [2025-12-28 09:34:39,641 E 1075 1098] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1075)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.584407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=1075)\u001b[0m \tRan out of time, early stopping on iteration 1157. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1075)\u001b[0m \t[997]\tvalid_set's binary_logloss: 0.584393\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t0.7249\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t172.75s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t47.57s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -3.74s of remaining time.\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/27.9 GB\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 1.0}\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t0.7249\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t12.85s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m \t0.17s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m AutoGluon training complete, total runtime = 897.24s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 470.7 rows/s (124445 batch size)\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/ag_diabetes_autml/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=177)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      LightGBM_BAG_L2       0.726318   0.724920     roc_auc       68.113594     264.362047  703.114315                10.097342               47.572789         172.749505            2       True          4\n",
      "1  WeightedEnsemble_L3       0.726318   0.724920     roc_auc       68.116476     264.529192  715.962632                 0.002881                0.167145          12.848316            3       True          5\n",
      "2    LightGBMXT_BAG_L2       0.708232   0.706344     roc_auc       63.956064     235.842569  621.914405                 5.939812               19.053311          91.549595            2       True          3\n",
      "3    LightGBMXT_BAG_L1       0.707893   0.706556     roc_auc       58.016252     216.789258  530.364810                58.016252              216.789258         530.364810            1       True          1\n",
      "4  WeightedEnsemble_L2       0.707893   0.706556     roc_auc       58.019326     216.966389  530.548588                 0.003074                0.177131           0.183778            2       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t996s\t = DyStack   runtime |\t2604s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 2604s\n",
      "AutoGluon will save models to \"/kaggle/working/ag_diabetes_autml\"\n",
      "Train Data Rows:    700000\n",
      "Train Data Columns: 24\n",
      "Label Column:       diagnosed_diabetes\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    29036.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 86.12 MB (0.3% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :  9 | ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', ...]\n",
      "\t\t('float', [])    :  5 | ['diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio']\n",
      "\t\t('int', [])      : 10 | ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'systolic_bp', 'diastolic_bp', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  :  6 | ['gender', 'ethnicity', 'education_level', 'income_level', 'smoking_status', ...]\n",
      "\t\t('float', [])     :  5 | ['diet_score', 'sleep_hours_per_day', 'screen_time_hours_per_day', 'bmi', 'waist_to_hip_ratio']\n",
      "\t\t('int', [])       : 10 | ['age', 'alcohol_consumption_per_week', 'physical_activity_minutes_per_week', 'systolic_bp', 'diastolic_bp', ...]\n",
      "\t\t('int', ['bool']) :  3 | ['family_history_diabetes', 'hypertension_history', 'cardiovascular_history']\n",
      "\t1.8s = Fit runtime\n",
      "\t24 features in original data used to generate 24 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 86.12 MB (0.3% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.91s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (110 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1734.46s of the 2602.32s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=1.97%)\n",
      "\t0.7095\t = Validation score   (roc_auc)\n",
      "\t1560.39s\t = Training   runtime\n",
      "\t913.94s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 52.24s of the 920.11s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.00%)\n",
      "\t0.7158\t = Validation score   (roc_auc)\n",
      "\t56.84s\t = Training   runtime\n",
      "\t10.36s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 852.03s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/28.3 GB\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.8, 'LightGBMXT_BAG_L1': 0.2}\n",
      "\t0.7162\t = Validation score   (roc_auc)\n",
      "\t9.64s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 842.14s of the 842.10s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.09%)\n",
      "\t0.7193\t = Validation score   (roc_auc)\n",
      "\t215.99s\t = Training   runtime\n",
      "\t49.8s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 608.73s of the 608.68s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=1, gpus=0, memory=2.12%)\n",
      "\t0.7247\t = Validation score   (roc_auc)\n",
      "\t393.74s\t = Training   runtime\n",
      "\t133.71s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 185.32s of the 185.28s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0, mem=3.3/28.3 GB\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 138 due to low time. Expected time usage reduced from 399.5s -> 184.8s...\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 100.03s compared to 70.4s of available time.\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L2.\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 14.51s of the 14.47s of remaining time.\n",
      "\tFitting 1 model on all data (use_child_oof=True) | Fitting with cpus=4, gpus=0, mem=3.3/28.1 GB\n",
      "\tWarning: Model is expected to require 465.2s to train, which exceeds the maximum time limit of 14.0s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 7.28s of remaining time.\n",
      "\tFitting 1 model on all data | Fitting with cpus=4, gpus=0, mem=0.0/28.3 GB\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.96, 'LightGBM_BAG_L1': 0.04}\n",
      "\t0.7247\t = Validation score   (roc_auc)\n",
      "\t19.52s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 2616.8s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 132.3 rows/s (140000 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/kaggle/working/ag_diabetes_autml\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ saved submission.csv\n",
      "       id  diagnosed_diabetes\n",
      "0  700000            0.480032\n",
      "1  700001            0.711253\n",
      "2  700002            0.749113\n",
      "3  700003            0.378291\n",
      "4  700004            0.938190\n",
      "\n",
      "=== AutoGluon Leaderboard (top) ===\n",
      "                 model  score_val eval_metric  pred_time_val     fit_time  \\\n",
      "0  WeightedEnsemble_L3   0.724724     roc_auc    1058.199718  2030.479530   \n",
      "1      LightGBM_BAG_L2   0.724722     roc_auc    1058.007900  2010.963446   \n",
      "2    LightGBMXT_BAG_L2   0.719268     roc_auc     974.095376  1833.215957   \n",
      "3  WeightedEnsemble_L2   0.716244     roc_auc     924.485374  1626.870094   \n",
      "4      LightGBM_BAG_L1   0.715805     roc_auc      10.358340    56.836127   \n",
      "5    LightGBMXT_BAG_L1   0.709546     roc_auc     913.937215  1560.390106   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                0.191818          19.516084            3       True   \n",
      "1              133.712346         393.737212            2       True   \n",
      "2               49.799822         215.989723            2       True   \n",
      "3                0.189820           9.643861            2       True   \n",
      "4               10.358340          56.836127            1       True   \n",
      "5              913.937215        1560.390106            1       True   \n",
      "\n",
      "   fit_order  \n",
      "0          6  \n",
      "1          5  \n",
      "2          4  \n",
      "3          3  \n",
      "4          2  \n",
      "5          1  \n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# #AutoML #AutoGluon #TabularData #BinaryClassification\n",
    "# #Kaggle #Ensembling #Stacking #ModelSelection #MachineLearning\n",
    "# ============================================================\n",
    "\n",
    "# If running on Kaggle: you can keep this install line\n",
    "!pip -q install -U \"autogluon.tabular>=1.1.0\"\n",
    "\n",
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "# -------------------------\n",
    "# Columns (as you specified)\n",
    "# -------------------------\n",
    "ID_COL = \"id\"\n",
    "TARGET = \"diagnosed_diabetes\"\n",
    "\n",
    "FEATURES = [\n",
    "    \"age\",\n",
    "    \"alcohol_consumption_per_week\",\n",
    "    \"physical_activity_minutes_per_week\",\n",
    "    \"diet_score\",\n",
    "    \"sleep_hours_per_day\",\n",
    "    \"screen_time_hours_per_day\",\n",
    "    \"bmi\",\n",
    "    \"waist_to_hip_ratio\",\n",
    "    \"systolic_bp\",\n",
    "    \"diastolic_bp\",\n",
    "    \"heart_rate\",\n",
    "    \"cholesterol_total\",\n",
    "    \"hdl_cholesterol\",\n",
    "    \"ldl_cholesterol\",\n",
    "    \"triglycerides\",\n",
    "    \"gender\",\n",
    "    \"ethnicity\",\n",
    "    \"education_level\",\n",
    "    \"income_level\",\n",
    "    \"smoking_status\",\n",
    "    \"employment_status\",\n",
    "    \"family_history_diabetes\",\n",
    "    \"hypertension_history\",\n",
    "    \"cardiovascular_history\",\n",
    "]\n",
    "\n",
    "CATEGORICAL = [\n",
    "    \"gender\",\n",
    "    \"ethnicity\",\n",
    "    \"education_level\",\n",
    "    \"income_level\",\n",
    "    \"smoking_status\",\n",
    "    \"employment_status\",\n",
    "    \"family_history_diabetes\",\n",
    "    \"hypertension_history\",\n",
    "    \"cardiovascular_history\",\n",
    "]\n",
    "NUMERIC = [c for c in FEATURES if c not in CATEGORICAL]\n",
    "\n",
    "# -------------------------\n",
    "# Helper: auto-find train/test\n",
    "# -------------------------\n",
    "def find_csv_by_name(root=\"/kaggle/input\", name=\"train.csv\"):\n",
    "    hits = glob.glob(os.path.join(root, \"**\", name), recursive=True)\n",
    "    return hits[0] if hits else None\n",
    "\n",
    "train_path = find_csv_by_name(name=\"train.csv\")\n",
    "test_path  = find_csv_by_name(name=\"test.csv\")\n",
    "\n",
    "# If your dataset uses different filenames, set them manually:\n",
    "train_path = \"/kaggle/input/playground-series-s5e12/train.csv\"\n",
    "test_path  = \"/kaggle/input/playground-series-s5e12/test.csv\"\n",
    "\n",
    "print(\"train_path:\", train_path)\n",
    "print(\"test_path :\", test_path)\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test  = pd.read_csv(test_path)\n",
    "\n",
    "# -------------------------\n",
    "# Basic sanity checks\n",
    "# -------------------------\n",
    "needed_train = [ID_COL, TARGET] + FEATURES\n",
    "missing_train = [c for c in needed_train if c not in train.columns]\n",
    "if missing_train:\n",
    "    raise ValueError(f\"Missing columns in train: {missing_train}\")\n",
    "\n",
    "needed_test = [ID_COL] + FEATURES\n",
    "missing_test = [c for c in needed_test if c not in test.columns]\n",
    "if missing_test:\n",
    "    raise ValueError(f\"Missing columns in test: {missing_test}\")\n",
    "\n",
    "# -------------------------\n",
    "# Type casting (helps AutoML)\n",
    "# -------------------------\n",
    "def cast_types(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # categoricals to \"category\"\n",
    "    for c in CATEGORICAL:\n",
    "        df[c] = df[c].astype(\"category\")\n",
    "\n",
    "    # numerics to float (coerce errors -> NaN)\n",
    "    for c in NUMERIC:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "    return df\n",
    "\n",
    "train = cast_types(train)\n",
    "test  = cast_types(test)\n",
    "\n",
    "# Ensure target is 0/1 int (if it isn't already)\n",
    "train[TARGET] = pd.to_numeric(train[TARGET], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# Use only required columns (prevents leakage from extra cols)\n",
    "train_ml = train[[ID_COL, TARGET] + FEATURES].copy()\n",
    "test_ml  = test[[ID_COL] + FEATURES].copy()\n",
    "\n",
    "# -------------------------\n",
    "# AutoGluon Tabular AutoML\n",
    "# -------------------------\n",
    "# Notes:\n",
    "# - If metric for the competition is unknown, ROC AUC is a solid default.\n",
    "# - If leaderboard uses logloss, you can switch eval_metric=\"log_loss\".\n",
    "predictor = TabularPredictor(\n",
    "    label=TARGET,\n",
    "    eval_metric=\"roc_auc\",\n",
    "    path=\"ag_diabetes_autml\",\n",
    "    verbosity=2\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data=train_ml.drop(columns=[ID_COL]),\n",
    "    presets=\"best_quality\",   # strong ensemble (bagging + stacking), slower but usually best\n",
    "    time_limit=60*60,         # 1 hour; adjust as needed\n",
    "    num_bag_folds=5,\n",
    "    num_stack_levels=1\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Predict probabilities\n",
    "# -------------------------\n",
    "proba = predictor.predict_proba(test_ml.drop(columns=[ID_COL]))\n",
    "\n",
    "# AutoGluon returns a DataFrame for binary classification with 2 columns (class labels).\n",
    "# We want probability of class \"1\" (positive).\n",
    "if isinstance(proba, pd.DataFrame):\n",
    "    # pick column 1 if it exists, else take the \"largest\" label column\n",
    "    if 1 in proba.columns:\n",
    "        pred = proba[1].to_numpy()\n",
    "    else:\n",
    "        # fallback: choose the column that corresponds to positive class\n",
    "        # (often '1', 'True', or the max label)\n",
    "        col = sorted(proba.columns)[-1]\n",
    "        pred = proba[col].to_numpy()\n",
    "else:\n",
    "    # fallback if returned as series/array\n",
    "    pred = np.asarray(proba)\n",
    "\n",
    "# -------------------------\n",
    "# Save submission\n",
    "# -------------------------\n",
    "sub = pd.DataFrame({ID_COL: test_ml[ID_COL].values, TARGET: pred})\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"✅ saved submission.csv\")\n",
    "print(sub.head())\n",
    "\n",
    "# Optional: show leaderboard of models\n",
    "lb = predictor.leaderboard(silent=True)\n",
    "print(\"\\n=== AutoGluon Leaderboard (top) ===\")\n",
    "print(lb.head(15))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 14272474,
     "sourceId": 91723,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31234,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4245.740453,
   "end_time": "2025-12-28T10:30:41.874006",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-28T09:19:56.133553",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
