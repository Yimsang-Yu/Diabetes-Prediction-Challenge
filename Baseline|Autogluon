{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91723,"databundleVersionId":14272474,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================================\n# #AutoML #AutoGluon #TabularData #BinaryClassification\n# #Kaggle #Ensembling #Stacking #ModelSelection #MachineLearning\n# ============================================================\n\n# If running on Kaggle: you can keep this install line\n!pip -q install -U \"autogluon.tabular>=1.1.0\"\n\nimport os, glob\nimport numpy as np\nimport pandas as pd\nfrom autogluon.tabular import TabularPredictor\n\n# -------------------------\n# Columns (as you specified)\n# -------------------------\nID_COL = \"id\"\nTARGET = \"diagnosed_diabetes\"\n\nFEATURES = [\n    \"age\",\n    \"alcohol_consumption_per_week\",\n    \"physical_activity_minutes_per_week\",\n    \"diet_score\",\n    \"sleep_hours_per_day\",\n    \"screen_time_hours_per_day\",\n    \"bmi\",\n    \"waist_to_hip_ratio\",\n    \"systolic_bp\",\n    \"diastolic_bp\",\n    \"heart_rate\",\n    \"cholesterol_total\",\n    \"hdl_cholesterol\",\n    \"ldl_cholesterol\",\n    \"triglycerides\",\n    \"gender\",\n    \"ethnicity\",\n    \"education_level\",\n    \"income_level\",\n    \"smoking_status\",\n    \"employment_status\",\n    \"family_history_diabetes\",\n    \"hypertension_history\",\n    \"cardiovascular_history\",\n]\n\nCATEGORICAL = [\n    \"gender\",\n    \"ethnicity\",\n    \"education_level\",\n    \"income_level\",\n    \"smoking_status\",\n    \"employment_status\",\n    \"family_history_diabetes\",\n    \"hypertension_history\",\n    \"cardiovascular_history\",\n]\nNUMERIC = [c for c in FEATURES if c not in CATEGORICAL]\n\n# -------------------------\n# Helper: auto-find train/test\n# -------------------------\ndef find_csv_by_name(root=\"/kaggle/input\", name=\"train.csv\"):\n    hits = glob.glob(os.path.join(root, \"**\", name), recursive=True)\n    return hits[0] if hits else None\n\ntrain_path = find_csv_by_name(name=\"train.csv\")\ntest_path  = find_csv_by_name(name=\"test.csv\")\n\n# If your dataset uses different filenames, set them manually:\ntrain_path = \"/kaggle/input/playground-series-s5e12/train.csv\"\ntest_path  = \"/kaggle/input/playground-series-s5e12/test.csv\"\n\nprint(\"train_path:\", train_path)\nprint(\"test_path :\", test_path)\n\ntrain = pd.read_csv(train_path)\ntest  = pd.read_csv(test_path)\n\n# -------------------------\n# Basic sanity checks\n# -------------------------\nneeded_train = [ID_COL, TARGET] + FEATURES\nmissing_train = [c for c in needed_train if c not in train.columns]\nif missing_train:\n    raise ValueError(f\"Missing columns in train: {missing_train}\")\n\nneeded_test = [ID_COL] + FEATURES\nmissing_test = [c for c in needed_test if c not in test.columns]\nif missing_test:\n    raise ValueError(f\"Missing columns in test: {missing_test}\")\n\n# -------------------------\n# Type casting (helps AutoML)\n# -------------------------\ndef cast_types(df: pd.DataFrame) -> pd.DataFrame:\n    df = df.copy()\n\n    # categoricals to \"category\"\n    for c in CATEGORICAL:\n        df[c] = df[c].astype(\"category\")\n\n    # numerics to float (coerce errors -> NaN)\n    for c in NUMERIC:\n        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n\n    return df\n\ntrain = cast_types(train)\ntest  = cast_types(test)\n\n# Ensure target is 0/1 int (if it isn't already)\ntrain[TARGET] = pd.to_numeric(train[TARGET], errors=\"coerce\").fillna(0).astype(int)\n\n# Use only required columns (prevents leakage from extra cols)\ntrain_ml = train[[ID_COL, TARGET] + FEATURES].copy()\ntest_ml  = test[[ID_COL] + FEATURES].copy()\n\n# -------------------------\n# AutoGluon Tabular AutoML\n# -------------------------\n# Notes:\n# - If metric for the competition is unknown, ROC AUC is a solid default.\n# - If leaderboard uses logloss, you can switch eval_metric=\"log_loss\".\npredictor = TabularPredictor(\n    label=TARGET,\n    eval_metric=\"roc_auc\",\n    path=\"ag_diabetes_autml\",\n    verbosity=2\n)\n\npredictor.fit(\n    train_data=train_ml.drop(columns=[ID_COL]),\n    presets=\"best_quality\",   # strong ensemble (bagging + stacking), slower but usually best\n    time_limit=60*60,         # 1 hour; adjust as needed\n    num_bag_folds=5,\n    num_stack_levels=1\n)\n\n# -------------------------\n# Predict probabilities\n# -------------------------\nproba = predictor.predict_proba(test_ml.drop(columns=[ID_COL]))\n\n# AutoGluon returns a DataFrame for binary classification with 2 columns (class labels).\n# We want probability of class \"1\" (positive).\nif isinstance(proba, pd.DataFrame):\n    # pick column 1 if it exists, else take the \"largest\" label column\n    if 1 in proba.columns:\n        pred = proba[1].to_numpy()\n    else:\n        # fallback: choose the column that corresponds to positive class\n        # (often '1', 'True', or the max label)\n        col = sorted(proba.columns)[-1]\n        pred = proba[col].to_numpy()\nelse:\n    # fallback if returned as series/array\n    pred = np.asarray(proba)\n\n# -------------------------\n# Save submission\n# -------------------------\nsub = pd.DataFrame({ID_COL: test_ml[ID_COL].values, TARGET: pred})\nsub.to_csv(\"submission.csv\", index=False)\n\nprint(\"âœ… saved submission.csv\")\nprint(sub.head())\n\n# Optional: show leaderboard of models\nlb = predictor.leaderboard(silent=True)\nprint(\"\\n=== AutoGluon Leaderboard (top) ===\")\nprint(lb.head(15))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-28T02:39:33.893521Z","iopub.execute_input":"2025-12-28T02:39:33.893824Z","iopub.status.idle":"2025-12-28T03:50:12.127153Z","shell.execute_reply.started":"2025-12-28T02:39:33.893792Z","shell.execute_reply":"2025-12-28T03:50:12.125839Z"}},"outputs":[],"execution_count":null}]}